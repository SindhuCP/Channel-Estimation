{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "GxhDahOZmwD6",
        "outputId": "6bb2a77a-ad2d-40c7-fa6b-c48762a64ae2"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Exception encountered when calling layer \"reshape_1\" (type Reshape).\n\ntotal size of new array must be unchanged, input_shape = [10000, 2, 2], output_shape = [1, 10000, 2]\n\nCall arguments received by layer \"reshape_1\" (type Reshape):\n  • inputs=tf.Tensor(shape=(None, 10000, 2, 2), dtype=float32)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-3e9b4f069fb2>\u001b[0m in \u001b[0;36m<cell line: 78>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;31m# Reshape output of Conv2D layers to match output_data shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m \u001b[0mreshape_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mReshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv3\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m##############################################################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreshape_layer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/layers/reshaping/reshape.py\u001b[0m in \u001b[0;36m_fix_unknown_dimension\u001b[0;34m(self, input_shape, output_shape)\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0moutput_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0munknown\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moriginal\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mknown\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0moriginal\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mknown\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput_shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling layer \"reshape_1\" (type Reshape).\n\ntotal size of new array must be unchanged, input_shape = [10000, 2, 2], output_shape = [1, 10000, 2]\n\nCall arguments received by layer \"reshape_1\" (type Reshape):\n  • inputs=tf.Tensor(shape=(None, 10000, 2, 2), dtype=float32)"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf # for deep learning framework\n",
        "from tensorflow.keras.layers import Input, Conv2D, Reshape # layers to build the cnn\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Generate QPSK Modulated Data\n",
        "N = 10000  # Number of QPSK symbols\n",
        "x = np.random.randint(0, 2, 2 * N)  # An array of random bits (0 or 1) of size 2*N\n",
        "\n",
        "# QPSK Modulation\n",
        "xmod = ((1 - 2*x[0::2]) + 1j * (1 - 2*x[1::2])) / np.sqrt(2)\n",
        "\n",
        "# Define SNR range from 0 to 40 dB\n",
        "snrdb_range = np.arange(0, 41, 1)\n",
        "ber = np.zeros_like(snrdb_range, dtype=float)  # Initialize BER array\n",
        "\n",
        "for idx, snrdb in enumerate(snrdb_range):\n",
        "    snrlin = 10**(snrdb / 10)\n",
        "\n",
        "    # Additive White Gaussian Noise (AWGN)\n",
        "    noise = (np.random.randn(N) + 1j * np.random.randn(N)) / np.sqrt(2)\n",
        "\n",
        "    # Received signal\n",
        "    yrx = xmod + np.sqrt(1/snrlin) * noise\n",
        "\n",
        "    # QPSK Demodulation\n",
        "    ydemod = np.zeros(2 * N, dtype=int)\n",
        "    ydemod[0::2] = np.real(yrx) < 0  # In-phase component\n",
        "    ydemod[1::2] = np.imag(yrx) < 0  # Quadrature component\n",
        "\n",
        "    # BER Calculation\n",
        "    ber[idx] = np.sum(np.not_equal(ydemod, x)) / N\n",
        "\n",
        "# CNN for QPSK Demodulation\n",
        "\n",
        "# Reshape data for CNN input\n",
        "xmod_real = np.real(xmod)\n",
        "xmod_imag = np.imag(xmod)\n",
        "xmod_noisy_real = np.real(yrx)\n",
        "xmod_noisy_imag = np.imag(yrx)\n",
        "\n",
        "# Concatenate real and imaginary parts\n",
        "input_data = np.stack((xmod_noisy_real, xmod_noisy_imag), axis=-1)\n",
        "\n",
        "# Reshape input_data to match CNN input shape\n",
        "input_data = input_data.reshape((1, N, 2, 1))\n",
        "\n",
        "#1: This represents the batch size (since we have a single batch of data).\n",
        "#N: The number of QPSK symbols.\n",
        "#2: The two features per symbol (real and imaginary parts).\n",
        "#1: The channel dimension, which is used to fit the expected input format for Conv2D layers in Keras (channels last format).\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Concatenate real and imaginary parts for output\n",
        "output_data = np.stack((xmod_real, xmod_imag), axis=-1)\n",
        "\n",
        "# Define CNN architecture\n",
        "input_layer = Input(shape=(N, 2, 1))  # Input layer for real and imaginary parts\n",
        "conv1 = Conv2D(16, (3, 3), padding='same', activation='relu')(input_layer)\n",
        "conv2 = Conv2D(32, (3, 3), padding='same', activation='relu')(conv1)\n",
        "conv3 = Conv2D(2, (3, 3), padding='same')(conv2)\n",
        "\n",
        "\n",
        "\n",
        "#16: Number of filters (feature maps) the convolutional layer will compute\n",
        "#(3, 3): Size of the convolutional kernel (3x3 window)\n",
        "#padding='same': Ensures that the output feature maps have the same spatial dimensions as the input by adding zero-padding where necessary\n",
        "\n",
        "#o/p of conv1:\n",
        "#1 is the batch size.\n",
        "#N is the number of symbols\n",
        "#2 is the second spatial dimension (features).\n",
        "#16 is the number of output channels (filters).\n",
        "\n",
        "\n",
        "# Reshape output of Conv2D layers to match output_data shape\n",
        "reshape_layer = Reshape((N, 2))(conv3) ##############################################################################################\n",
        "\n",
        "model = Model(inputs=input_layer, outputs=reshape_layer)\n",
        "\n",
        "# Compile the model\n",
        "#model.compile(optimizer=Adam(),loss='mean_squared_error')\n",
        "\n",
        "# Train the model (you may need to adjust batch size and number of epochs based on your system's capabilities)\n",
        "model.fit(input_data, output_data,\n",
        "          epochs=10,\n",
        "          batch_size=64,\n",
        "          shuffle=True)\n",
        "\n",
        "# Test the model\n",
        "ypred = model.predict(input_data)\n",
        "\n",
        "# Calculate BER for predicted symbols\n",
        "ypred_real = np.squeeze(ypred[:, :, 0])\n",
        "ypred_imag = np.squeeze(ypred[:, :, 1])\n",
        "\n",
        "ypred_demod = np.zeros(2 * N, dtype=int)\n",
        "ypred_demod[0::2] = ypred_real.flatten() < 0  # In-phase component\n",
        "ypred_demod[1::2] = ypred_imag.flatten() < 0  # Quadrature component\n",
        "\n",
        "ber_cnn = np.sum(np.not_equal(ypred_demod, x)) / N\n",
        "\n",
        "print(f'BER using CNN: {ber_cnn:.6f}')\n"
      ]
    }
  ]
}